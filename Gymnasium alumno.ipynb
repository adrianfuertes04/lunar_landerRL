{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ce62d5d",
   "metadata": {},
   "source": [
    "### Recursos\n",
    "\n",
    "Problemas interesantes para Aprendizaje por refuerzo\n",
    " * Gymnasium: https://gymnasium.farama.org/environments/box2d/\n",
    " * Solución del Lunar Lander con DQN: https://shiva-verma.medium.com/solving-lunar-lander-openaigym-reinforcement-learning-785675066197\n",
    " * Otra solución: https://wingedsheep.com/lunar-lander-dqn/ y https://github.com/wingedsheep/blog/blob/main/lunar-lander-dqn/lunar_lander_dqn_blog.ipynb\n",
    " * The Nature of Code: https://youtu.be/lu5ul7z4icQ\n",
    " * Librería para neuroevolución: https://pypi.org/project/nevopy/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57c172cf-929c-4be0-b79e-d3da9d17c343",
   "metadata": {},
   "source": [
    "## Instalación\n",
    "\n",
    "%pip install gymnasium  \n",
    "%pip install gymnasium[box2d] \n",
    "\n",
    "### Acciones adicionales\n",
    "\n",
    "#### En macos\n",
    "\n",
    "pip uninstall swig  \n",
    "xcode-select -—install (si no se tienen ya)  \n",
    "pip install swig  / sudo port install swig-python\n",
    "pip install 'gymnasium[box2d]' # en zsh hay que poner las comillas  \n",
    "\n",
    "Si se da el error [NSCheapMutableString initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead.  \n",
    "Hacer  \n",
    "OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n",
    "\n",
    "#### en Windows\n",
    "\n",
    "Si da error, se debe a la falta de la versión correcta de Microsoft Visual C++ Build Tools, que es una dependencia de Box2D. Para solucionar este problema, puede seguir los siguientes pasos:  \n",
    " * Descargar Microsoft Visual C++ Build Tools desde https://visualstudio.microsoft.com/visual-cpp-build-tools/.\n",
    " * Dentro de la app, seleccione la opción \"Herramientas de compilación de C++\" para instalar.\n",
    " * Reinicie su sesión en Jupyter Notebook.\n",
    " * Ejecute nuevamente el comando !pip install gymnasium[box2d] en la línea de comandos de su notebook.\n",
    "\n",
    "También puede deberse a no tener swig instalado o a tener una versión incorrecta, en ese caso habrá que instalarlo con\n",
    "\n",
    "%pip uninstall swig  \n",
    "%pip install swig\n",
    "\n",
    "Si nada funciona, la solución última es instalar anaconda y cambiar el kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e7a384-a993-4330-b213-03d2f02ed3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba lunar lander por humano\n",
    "# apartado A de la práctica\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium.utils.play\n",
    "\n",
    "lunar_lander_keys = {\n",
    "    (pygame.K_UP,): 2,\n",
    "    (pygame.K_LEFT,): 1,\n",
    "    (pygame.K_RIGHT,): 3,\n",
    "}\n",
    "gymnasium.utils.play.play(env, zoom=3, keys_to_action=lunar_lander_keys, noop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cbb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agente deliberativo\n",
    "# Apartado B de la práctica\n",
    "\n",
    "# observaciones [x, y, vx, vy, ang, vang, pataiz, parader]\n",
    "# acciones [nada, derecho, central, izquierdo]\n",
    "\n",
    "# IMPORTANTE: tiene que ser creado por vosotros mismos, no vale la solución de OpenAI!\n",
    "\n",
    "def policy(observation):\n",
    "    x, y, vx, vy, angle, angular_velocity, left_leg, right_leg = observation\n",
    "\n",
    "    # Ajustar el ángulo\n",
    "    if angle > 0.05:\n",
    "        print('⮕', end='')\n",
    "        return 3  # Motor derecho\n",
    "    elif angle < -0.05:\n",
    "        print('⬅︎', end='')\n",
    "        return 1  # Motor izquierdo\n",
    "\n",
    "    # Controlar la velocidad vertical\n",
    "    if vy < -0.2:\n",
    "        print('⬆︎', end='')\n",
    "        return 2  # Motor principal\n",
    "    elif vy > 0.1:\n",
    "        print('–', end='')\n",
    "        return 0 # no hacer nada.\n",
    "\n",
    "    # Controlar la velocidad horizontal\n",
    "    if vx > 0.1:\n",
    "      print('⬅︎', end='')\n",
    "      return 1\n",
    "    elif vx < -0.1:\n",
    "      print('⮕', end='')\n",
    "      return 3\n",
    "\n",
    "    print('–', end='')\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle de simulación\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset()\n",
    "terminated, truncated = False, False\n",
    "total_reward = 0\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    action = policy(observation)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    env.render() # Muestra el entorno en tiempo real\n",
    "\n",
    "print(f\"Recompensa total: {total_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3249b",
   "metadata": {},
   "source": [
    "### Importante:\n",
    "\n",
    "Después de la evolución, para poder probar la red obtenido, dejar en la varoable global model la red óptima encontrada\n",
    "\n",
    "model = ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "872b9955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 5: Recompensa promedio  = -84.10731468193967\n",
      "Episodio 10: Recompensa promedio  = -41.919480066557625\n",
      "Episodio 15: Recompensa promedio  = -53.49174413102128\n",
      "Episodio 20: Recompensa promedio  = -24.76425482217428\n",
      "Episodio 25: Recompensa promedio  = -66.69375351764094\n",
      "Episodio 30: Recompensa promedio  = -56.14360547307092\n",
      "Episodio 35: Recompensa promedio  = -65.25420515792993\n",
      "Episodio 40: Recompensa promedio  = -29.15008316812643\n",
      "Episodio 45: Recompensa promedio  = -53.76038052238876\n",
      "Episodio 50: Recompensa promedio  = -54.15575862521911\n",
      "Episodio 55: Recompensa promedio  = -62.0844239482484\n",
      "Episodio 60: Recompensa promedio  = -36.60984321626369\n",
      "Episodio 65: Recompensa promedio  = -39.223906291131335\n",
      "Episodio 70: Recompensa promedio  = -44.54880639078018\n",
      "Episodio 75: Recompensa promedio  = -49.242186256533884\n",
      "Episodio 80: Recompensa promedio  = -42.81293629127\n",
      "Episodio 85: Recompensa promedio  = 2.2663999545574685\n",
      "Episodio 90: Recompensa promedio  = -25.26688113772241\n",
      "Episodio 95: Recompensa promedio  = -56.29599025948248\n",
      "Episodio 100: Recompensa promedio  = -42.35556275305096\n",
      "Episodio 105: Recompensa promedio  = -16.243044219078968\n",
      "Episodio 110: Recompensa promedio  = -45.57245725599195\n",
      "Episodio 115: Recompensa promedio  = -38.52683645319438\n",
      "Episodio 120: Recompensa promedio  = 1.5705290750214203\n",
      "Episodio 125: Recompensa promedio  = -18.27229363608388\n",
      "Episodio 130: Recompensa promedio  = -29.95100914527522\n",
      "Episodio 135: Recompensa promedio  = -6.411479081936889\n",
      "Episodio 140: Recompensa promedio  = -29.300633657253023\n",
      "Episodio 145: Recompensa promedio  = 0.9920305213826793\n",
      "Episodio 150: Recompensa promedio  = 125.44907908575333\n",
      "Episodio 155: Recompensa promedio  = 69.04550836459366\n",
      "Episodio 160: Recompensa promedio  = 22.999910288162994\n",
      "Episodio 165: Recompensa promedio  = 120.66871420154773\n",
      "Episodio 170: Recompensa promedio  = 19.00505838098862\n",
      "Episodio 175: Recompensa promedio  = -0.5935772862955162\n",
      "Episodio 180: Recompensa promedio  = 47.68312757061683\n",
      "Episodio 185: Recompensa promedio  = 76.90875009742318\n",
      "Episodio 190: Recompensa promedio  = 36.89066963779983\n",
      "Episodio 195: Recompensa promedio  = 42.870602497440196\n",
      "Episodio 200: Recompensa promedio  = 62.64428542070882\n",
      "Episodio 205: Recompensa promedio  = 29.570992412095023\n",
      "Episodio 210: Recompensa promedio  = 96.26637653172695\n",
      "Episodio 215: Recompensa promedio  = 46.37712857083441\n",
      "Episodio 220: Recompensa promedio  = 38.443092186948334\n",
      "Episodio 225: Recompensa promedio  = 81.67525797303611\n",
      "Episodio 230: Recompensa promedio  = 84.22162192196573\n",
      "Episodio 235: Recompensa promedio  = 58.50318104068863\n",
      "Episodio 240: Recompensa promedio  = 54.46406413096473\n",
      "Episodio 245: Recompensa promedio  = 84.27103863129446\n",
      "Episodio 250: Recompensa promedio  = 129.34913190248864\n",
      "Episodio 255: Recompensa promedio  = 72.25380028932693\n",
      "Episodio 260: Recompensa promedio  = 149.0281545047071\n",
      "Episodio 265: Recompensa promedio  = 133.12951007068742\n",
      "Episodio 270: Recompensa promedio  = 121.38059311977592\n",
      "Episodio 275: Recompensa promedio  = 271.8371578774951\n",
      "Episodio 280: Recompensa promedio  = 168.4562721229777\n",
      "Episodio 285: Recompensa promedio  = 250.18014778970746\n",
      "Episodio 290: Recompensa promedio  = 210.3065684659285\n",
      "Episodio 295: Recompensa promedio  = 129.18078162595344\n",
      "Episodio 300: Recompensa promedio  = 140.05565958926357\n",
      "Episodio 305: Recompensa promedio  = 204.85094175229477\n",
      "Episodio 310: Recompensa promedio  = 195.22952042516\n",
      "Episodio 315: Recompensa promedio  = 201.42738907434483\n",
      "Episodio 320: Recompensa promedio  = 177.9490001813583\n",
      "Episodio 325: Recompensa promedio  = 183.3395414362724\n",
      "Episodio 330: Recompensa promedio  = 191.00268790783113\n",
      "Episodio 335: Recompensa promedio  = 193.6557796815481\n",
      "Episodio 340: Recompensa promedio  = 264.2852728767023\n",
      "Episodio 345: Recompensa promedio  = 221.60556803918107\n",
      "Episodio 350: Recompensa promedio  = 233.556875838026\n",
      "Episodio 355: Recompensa promedio  = 248.7994772984317\n",
      "Episodio 360: Recompensa promedio  = 275.46101061183515\n",
      "Episodio 365: Recompensa promedio  = 271.56253515905325\n",
      "Episodio 370: Recompensa promedio  = 251.74567534259512\n",
      "Episodio 375: Recompensa promedio  = 263.9823675064762\n",
      "Episodio 380: Recompensa promedio  = 254.47967787058502\n",
      "Episodio 385: Recompensa promedio  = 262.094821918002\n",
      "Episodio 390: Recompensa promedio  = 255.97660384635634\n",
      "Episodio 395: Recompensa promedio  = 269.11332585560115\n",
      "Episodio 400: Recompensa promedio  = 277.083593377983\n",
      "Episodio 405: Recompensa promedio  = 274.46178724001186\n",
      "Episodio 410: Recompensa promedio  = 269.73692960815606\n",
      "Episodio 415: Recompensa promedio  = 261.0486131186947\n",
      "Episodio 420: Recompensa promedio  = 243.7042124146422\n",
      "Episodio 425: Recompensa promedio  = 274.108654341111\n",
      "Episodio 430: Recompensa promedio  = 275.14762467746607\n",
      "Episodio 435: Recompensa promedio  = 265.5574411068993\n",
      "Episodio 440: Recompensa promedio  = 266.8490720672691\n",
      "Episodio 445: Recompensa promedio  = 286.5739084633748\n",
      "Episodio 450: Recompensa promedio  = 287.2182501553779\n",
      "Episodio 455: Recompensa promedio  = 259.9991697595333\n",
      "Episodio 460: Recompensa promedio  = 266.1417179626349\n",
      "Episodio 465: Recompensa promedio  = 266.2338877234135\n",
      "Episodio 470: Recompensa promedio  = 271.3742337376401\n",
      "Episodio 475: Recompensa promedio  = 262.44274669772716\n",
      "Episodio 480: Recompensa promedio  = 271.6497608256265\n",
      "Episodio 485: Recompensa promedio  = 257.7835215711684\n",
      "Episodio 490: Recompensa promedio  = 263.58495689724833\n",
      "Episodio 495: Recompensa promedio  = 265.6150163012502\n",
      "Episodio 500: Recompensa promedio  = 269.909925549643\n",
      "Episodio 505: Recompensa promedio  = 274.58496064762704\n",
      "Episodio 510: Recompensa promedio  = 287.3392891389039\n",
      "Episodio 515: Recompensa promedio  = 279.2898852389508\n",
      "Episodio 520: Recompensa promedio  = 266.56256229293797\n",
      "Episodio 525: Recompensa promedio  = 265.2369724078822\n",
      "Episodio 530: Recompensa promedio  = 272.9789055738787\n",
      "Episodio 535: Recompensa promedio  = 268.49863924727737\n",
      "Episodio 540: Recompensa promedio  = 275.4867769684521\n",
      "Episodio 545: Recompensa promedio  = 268.27047302193023\n",
      "Episodio 550: Recompensa promedio  = 279.8601723550152\n",
      "Episodio 555: Recompensa promedio  = 265.4981996435814\n",
      "Episodio 560: Recompensa promedio  = 272.6387379269873\n",
      "Episodio 565: Recompensa promedio  = 278.5653109660783\n",
      "Episodio 570: Recompensa promedio  = 281.885716913317\n",
      "Episodio 575: Recompensa promedio  = 279.74234098082434\n",
      "Episodio 580: Recompensa promedio  = 272.21424694031657\n",
      "Episodio 585: Recompensa promedio  = 281.6119934476368\n",
      "Episodio 590: Recompensa promedio  = 274.04035870687846\n",
      "Episodio 595: Recompensa promedio  = 276.1981645354714\n",
      "Episodio 600: Recompensa promedio  = 290.0582016719124\n",
      "Episodio 605: Recompensa promedio  = 281.14061016381686\n",
      "Episodio 610: Recompensa promedio  = 282.5345708794511\n",
      "Episodio 615: Recompensa promedio  = 285.5802023873824\n",
      "Episodio 620: Recompensa promedio  = 280.15715133428563\n",
      "Episodio 625: Recompensa promedio  = 286.3846917741724\n",
      "Episodio 630: Recompensa promedio  = 285.1544800988258\n",
      "Episodio 635: Recompensa promedio  = 278.55282397415016\n",
      "Episodio 640: Recompensa promedio  = 277.8379262233281\n",
      "Episodio 645: Recompensa promedio  = 284.3430245490389\n",
      "Episodio 650: Recompensa promedio  = 285.9288204468954\n",
      "Episodio 655: Recompensa promedio  = 282.3031342063902\n",
      "Episodio 660: Recompensa promedio  = 289.2416223335378\n",
      "Episodio 665: Recompensa promedio  = 298.75788961984165\n",
      "Episodio 670: Recompensa promedio  = 283.52838667793884\n",
      "Episodio 675: Recompensa promedio  = 286.5605185988876\n",
      "Episodio 680: Recompensa promedio  = 279.1907162385702\n",
      "Episodio 685: Recompensa promedio  = 279.75362345544846\n",
      "Episodio 690: Recompensa promedio  = 284.83541521357733\n",
      "Episodio 695: Recompensa promedio  = 286.38641216421695\n",
      "Episodio 700: Recompensa promedio  = 280.59050834665845\n",
      "Episodio 705: Recompensa promedio  = 284.91101051628976\n",
      "Episodio 710: Recompensa promedio  = 283.36988511942\n",
      "Episodio 715: Recompensa promedio  = 287.95899379774846\n",
      "Episodio 720: Recompensa promedio  = 285.09976316719934\n",
      "Episodio 725: Recompensa promedio  = 288.73074643889686\n",
      "Episodio 730: Recompensa promedio  = 287.5723182254864\n",
      "Episodio 735: Recompensa promedio  = 287.2300023256128\n",
      "Episodio 740: Recompensa promedio  = 284.3046173032459\n",
      "Episodio 745: Recompensa promedio  = 290.01670790145806\n",
      "Episodio 750: Recompensa promedio  = 291.89489636871275\n",
      "Episodio 755: Recompensa promedio  = 287.9226541947969\n",
      "Episodio 760: Recompensa promedio  = 296.10491375759386\n",
      "Episodio 765: Recompensa promedio  = 284.2617660430181\n",
      "Episodio 770: Recompensa promedio  = 296.3556523401027\n",
      "Episodio 775: Recompensa promedio  = 283.025315793241\n",
      "Episodio 780: Recompensa promedio  = 283.9098436221124\n",
      "Episodio 785: Recompensa promedio  = 290.43984807980706\n",
      "Episodio 790: Recompensa promedio  = 286.4833874647013\n",
      "Episodio 795: Recompensa promedio  = 289.74010866080755\n",
      "Episodio 800: Recompensa promedio  = 287.32798001957946\n",
      "Episodio 805: Recompensa promedio  = 286.76819596050393\n",
      "Episodio 810: Recompensa promedio  = 293.42047297090295\n",
      "Episodio 815: Recompensa promedio  = 291.84278190709796\n",
      "Episodio 820: Recompensa promedio  = 287.6326327518789\n",
      "Episodio 825: Recompensa promedio  = 289.04114814749994\n",
      "Episodio 830: Recompensa promedio  = 292.51131177188745\n",
      "Episodio 835: Recompensa promedio  = 286.6386370819897\n",
      "Episodio 840: Recompensa promedio  = 286.4041420231471\n",
      "Episodio 845: Recompensa promedio  = 288.9354295539232\n",
      "Episodio 850: Recompensa promedio  = 286.4042652947849\n",
      "Episodio 855: Recompensa promedio  = 288.15613141294597\n",
      "Episodio 860: Recompensa promedio  = 293.7531290440722\n",
      "Episodio 865: Recompensa promedio  = 286.87820020831066\n",
      "Episodio 870: Recompensa promedio  = 288.05383812067254\n",
      "Episodio 875: Recompensa promedio  = 285.8497431894575\n",
      "Episodio 880: Recompensa promedio  = 289.882399511711\n",
      "Episodio 885: Recompensa promedio  = 286.0702388219775\n",
      "Episodio 890: Recompensa promedio  = 291.17396599608327\n",
      "Episodio 895: Recompensa promedio  = 298.6587623189412\n",
      "Episodio 900: Recompensa promedio  = 289.31436861489476\n",
      "Episodio 905: Recompensa promedio  = 289.0346370065607\n",
      "Episodio 910: Recompensa promedio  = 288.9266922219316\n",
      "Episodio 915: Recompensa promedio  = 287.2951529532179\n",
      "Episodio 920: Recompensa promedio  = 284.9102878966612\n",
      "Episodio 925: Recompensa promedio  = 292.1586767641919\n",
      "Episodio 930: Recompensa promedio  = 292.960857782934\n",
      "Episodio 935: Recompensa promedio  = 286.46612073734605\n",
      "Episodio 940: Recompensa promedio  = 287.5423732546714\n",
      "Episodio 945: Recompensa promedio  = 294.6106234231157\n",
      "Episodio 950: Recompensa promedio  = 288.11876653146516\n",
      "Episodio 955: Recompensa promedio  = 294.5342714079576\n",
      "Episodio 960: Recompensa promedio  = 292.63343431796534\n",
      "Episodio 965: Recompensa promedio  = 287.81840928458917\n",
      "Episodio 970: Recompensa promedio  = 294.56009129611766\n",
      "Episodio 975: Recompensa promedio  = 295.14713894989205\n",
      "Episodio 980: Recompensa promedio  = 294.7432214819125\n",
      "Episodio 985: Recompensa promedio  = 298.1070676632943\n",
      "Episodio 990: Recompensa promedio  = 292.6986299751506\n",
      "Episodio 995: Recompensa promedio  = 293.17804773048846\n",
      "Episodio 1000: Recompensa promedio  = 293.71560043121985\n",
      "Episodio 1005: Recompensa promedio  = 301.7541451137232\n",
      "Episodio 1010: Recompensa promedio  = 289.5600290764519\n",
      "Episodio 1015: Recompensa promedio  = 301.0907752481301\n",
      "Episodio 1020: Recompensa promedio  = 292.5967909189048\n",
      "Episodio 1025: Recompensa promedio  = 290.55950964305805\n",
      "Episodio 1030: Recompensa promedio  = 289.67256194255026\n",
      "Episodio 1035: Recompensa promedio  = 288.4877073195547\n",
      "Episodio 1040: Recompensa promedio  = 284.6475695724606\n",
      "Episodio 1045: Recompensa promedio  = 296.89863458291774\n",
      "Episodio 1050: Recompensa promedio  = 291.51662074011693\n",
      "Episodio 1055: Recompensa promedio  = 293.6393741436139\n",
      "Episodio 1060: Recompensa promedio  = 291.8523759153845\n",
      "Episodio 1065: Recompensa promedio  = 289.3708035190965\n",
      "Episodio 1070: Recompensa promedio  = 293.5220296819834\n",
      "Episodio 1075: Recompensa promedio  = 292.6426457009689\n",
      "Episodio 1080: Recompensa promedio  = 296.80990536523257\n",
      "Episodio 1085: Recompensa promedio  = 294.37066689585015\n",
      "Episodio 1090: Recompensa promedio  = 286.32525174823246\n",
      "Episodio 1095: Recompensa promedio  = 288.69915034525445\n",
      "Episodio 1100: Recompensa promedio  = 294.16183120492656\n",
      "Episodio 1105: Recompensa promedio  = 296.1543008030379\n",
      "Episodio 1110: Recompensa promedio  = 288.02025917936464\n",
      "Episodio 1115: Recompensa promedio  = 289.62028545338114\n",
      "Episodio 1120: Recompensa promedio  = 290.8458036064714\n",
      "Episodio 1125: Recompensa promedio  = 288.9463603525558\n",
      "Episodio 1130: Recompensa promedio  = 300.97338016817554\n",
      "Episodio 1135: Recompensa promedio  = 294.5323193269605\n",
      "Episodio 1140: Recompensa promedio  = 292.98474790313065\n",
      "Episodio 1145: Recompensa promedio  = 288.02092650700035\n",
      "Episodio 1150: Recompensa promedio  = 296.3460726545587\n",
      "Episodio 1155: Recompensa promedio  = 292.57719666820043\n",
      "Episodio 1160: Recompensa promedio  = 292.32119485947356\n",
      "Episodio 1165: Recompensa promedio  = 292.98372663848966\n",
      "Episodio 1170: Recompensa promedio  = 287.35486146026693\n",
      "Episodio 1175: Recompensa promedio  = 288.809064342321\n",
      "Episodio 1180: Recompensa promedio  = 287.6582010094462\n",
      "Episodio 1185: Recompensa promedio  = 291.2129641043912\n",
      "Episodio 1190: Recompensa promedio  = 287.46730833243\n",
      "Episodio 1195: Recompensa promedio  = 293.24058016641914\n",
      "Episodio 1200: Recompensa promedio  = 289.3208264413398\n",
      "Episodio 1205: Recompensa promedio  = 285.67365757693466\n",
      "Episodio 1210: Recompensa promedio  = 287.99690458629004\n",
      "Episodio 1215: Recompensa promedio  = 286.68021721220885\n",
      "Episodio 1220: Recompensa promedio  = 294.3000094687305\n",
      "Episodio 1225: Recompensa promedio  = 291.7644096344145\n",
      "Episodio 1230: Recompensa promedio  = 289.3656856800161\n",
      "Episodio 1235: Recompensa promedio  = 295.4811904740746\n",
      "Episodio 1240: Recompensa promedio  = 294.9924874616821\n",
      "Episodio 1245: Recompensa promedio  = 288.5543691827933\n",
      "Episodio 1250: Recompensa promedio  = 291.68994376469243\n"
     ]
    }
   ],
   "source": [
    "# neuroevolución con MLP y algoritmo genético\n",
    "# Apartado C de la práctica\n",
    "\n",
    "import numpy as np\n",
    "from MLP import MLP\n",
    "import random\n",
    "\n",
    "# Configuración del algoritmo genético\n",
    "POPULATION_SIZE = 500\n",
    "GENERATIONS = 250\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Crear población inicial\n",
    "population = [MLP([8, 6, 4]) for _ in range(POPULATION_SIZE)]\n",
    "\n",
    "def evaluate_fitness(model):\n",
    "    env = gym.make(\"LunarLander-v3\")\n",
    "    total_reward = 0\n",
    "    for _ in range(5):  # Evaluar el modelo en 5 episodios\n",
    "        observation, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = np.argmax(model.forward(observation))\n",
    "            observation, reward, terminated, truncated, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            done = terminated or truncated\n",
    "    env.close()\n",
    "    return total_reward\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    ch1 = parent1.to_chromosome()\n",
    "    ch2 = parent2.to_chromosome()\n",
    "    point = random.randint(0, len(ch1) - 1)\n",
    "    child_ch = ch1[:point] + ch2[point:]\n",
    "    child = MLP([8, 6, 4])\n",
    "    child.from_chromosome(child_ch)\n",
    "    return child\n",
    "\n",
    "def mutate(model):\n",
    "    ch = model.to_chromosome()\n",
    "    for i in range(len(ch)):\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            ch[i] += np.random.normal(0, 0.1)\n",
    "    model.from_chromosome(ch)\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "    # Evaluar fitness\n",
    "    fitness = [evaluate_fitness(model) for model in population]\n",
    "    ranked_population = [model for _, model in sorted(zip(fitness, population), reverse=True)]\n",
    "\n",
    "    # Seleccionar los mejores individuos\n",
    "    population = ranked_population[:POPULATION_SIZE // 2]\n",
    "\n",
    "    # Reproducción\n",
    "    while len(population) < POPULATION_SIZE:\n",
    "        parent1, parent2 = random.sample(population[:POPULATION_SIZE // 4], 2)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        population.append(child)\n",
    "\n",
    "    print(f\"Episodio {5*(generation + 1)}: Recompensa promedio  = {max(fitness)/5}\")\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "best_model = population[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fcf37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  # Importar el módulo para guardar el modelo\n",
    "\n",
    "\n",
    "with open(\"best_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4939249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1:\n",
      "Recompensa acumulada: 288.41109682610664, Fitness calculado: 0.9768221936522132\n",
      "Recompensa total del episodio 1: 288.41109682610664\n",
      "Episodio 2:\n",
      "Recompensa acumulada: 288.5613030492823, Fitness calculado: 0.9771226060985646\n",
      "Recompensa total del episodio 2: 288.5613030492823\n",
      "Episodio 3:\n",
      "Recompensa acumulada: 289.2691087581363, Fitness calculado: 0.9785382175162727\n",
      "Recompensa total del episodio 3: 289.2691087581363\n",
      "Episodio 4:\n",
      "Recompensa acumulada: 241.81610034007412, Fitness calculado: 0.8836322006801482\n",
      "Recompensa total del episodio 4: 241.81610034007412\n",
      "Episodio 5:\n",
      "Recompensa acumulada: 284.1131360988793, Fitness calculado: 0.9682262721977586\n",
      "Recompensa total del episodio 5: 284.1131360988793\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Función para ejecutar el mejor modelo en un episodio\n",
    "def run(env, model):\n",
    "    observation, info = env.reset()\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = np.argmax(model.forward(observation))  # Seleccionar la mejor acción\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        racum += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            r = (racum + 200) / 500\n",
    "            print(f\"Recompensa acumulada: {racum}, Fitness calculado: {r}\")\n",
    "            return racum\n",
    "\n",
    "# Configurar el entorno para grabar videos\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "\n",
    "# Probar el mejor modelo en 5 episodios\n",
    "for episode in range(5):\n",
    "    print(f\"Episodio {episode + 1}:\")\n",
    "    total_reward = run(env, best_model)  # Usar la función `run` con el mejor modelo\n",
    "    print(f\"Recompensa total del episodio {episode + 1}: {total_reward}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bddce4",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7057970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# walker\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\") # hardcore=True\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799154c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
